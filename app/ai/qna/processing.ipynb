{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf2 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (1.25.2)\n",
      "Requirement already satisfied: openai in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (0.27.8)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (4.4.0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (1.26.14)\n",
      "Requirement already satisfied: loguru>=0.5.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (2.28.2)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (2.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.4 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (6.0.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf2 pinecone-client scikit-learn tiktoken numpy openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuce\\PycharmProjects\\StudyHub-server\\venv\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "import tiktoken\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "from numpy import array, average\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDINGS_MODEL = \"text-embedding-ada-002\"\n",
    "GENERATIVE_MODEL = \"gpt-3.5-turbo\"\n",
    "EMBEDDING_DIMENSION = 1536\n",
    "TEXT_EMBEDDING_CHUNK_SIZE = 200\n",
    "COSINE_SIM_THRESHOLD = 0.7\n",
    "MAX_TEXTS_TO_EMBED_BATCH_SIZE = 100\n",
    "MAX_PINECONE_VECTORS_TO_UPSERT_PATCH_SIZE = 100\n",
    "TOP_K = 5\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "pinecone.init(api_key=os.getenv('PINECONE_API_KEY'), environment='gcp-starter')\n",
    "pinecone_index = pinecone.Index('studyhub')\n",
    "print(pinecone_index.describe_index_stats())\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "file_text_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def chunks(text, n):\n",
    "    \"\"\"\n",
    "    Yield successive n-sized chunks from text,\n",
    "    preferably ending at the end of a sentence.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.encode(text)\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            # Decode the tokens and check for full stop or newline\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        # If no end of sentence found, use n tokens as the chunk size\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n",
    "\n",
    "\n",
    "def get_col_average_from_list_of_lists(list_of_lists):\n",
    "    \"\"\"\n",
    "    Compute the column-wise average of a list of lists\n",
    "    \"\"\"\n",
    "    if len(list_of_lists) == 1:\n",
    "        return list_of_lists[0]\n",
    "    else:\n",
    "        list_of_lists_array = array(list_of_lists)\n",
    "        average_embedding = average(list_of_lists_array, axis=0)\n",
    "        return average_embedding.tolist()\n",
    "\n",
    "\n",
    "def create_embeddings_for_text(text):\n",
    "    \"\"\"\n",
    "    Create embeddings for a text using a tokenizer and an OpenAI engine.\n",
    "    Return a list of tuples (text_chunk, embedding) and an average embedding for a text.\n",
    "    \"\"\"\n",
    "    token_chunks = list(chunks(text, TEXT_EMBEDDING_CHUNK_SIZE))\n",
    "    text_chunks = [tokenizer.decode(chunk) for chunk in token_chunks]\n",
    "\n",
    "    # Split text_chunks into shorter arrays of max length 10\n",
    "    text_chunks_arrays = [text_chunks[i:i+MAX_TEXTS_TO_EMBED_BATCH_SIZE] for i in range(0, len(text_chunks), MAX_TEXTS_TO_EMBED_BATCH_SIZE)]\n",
    "\n",
    "    # Call get_embeddings for each shorter array and combine the results\n",
    "    embeddings = []\n",
    "    for text_chunks_array in text_chunks_arrays:\n",
    "        embeddings_response = get_embeddings(text_chunks_array, EMBEDDINGS_MODEL)\n",
    "        embeddings.extend([embedding[\"embedding\"] for embedding in embeddings_response])\n",
    "\n",
    "    text_embeddings = list(zip(text_chunks, embeddings))\n",
    "\n",
    "    average_embedding = get_col_average_from_list_of_lists(embeddings)\n",
    "\n",
    "    return text_embeddings, average_embedding\n",
    "\n",
    "def read_file(filename):\n",
    "  if filename.endswith('.pdf'):\n",
    "    reader = PdfReader(os.path.join('data', filename))\n",
    "    extracted_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        extracted_text += page.extract_text()\n",
    "  elif filename.endswith('.txt'):\n",
    "    with open(os.path.join('data', filename), 'r') as fp:\n",
    "      extracted_text = fp.read()\n",
    "\n",
    "  file_text_dict[filename[:-4]] = extracted_text\n",
    "\n",
    "  clean_text = extracted_text.replace('\\uf0b7', ' ').replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"  \", \" \")\n",
    "  return f'Topic is {filename[:-4]}; {clean_text}'\n",
    "\n",
    "\n",
    "def get_embedding(text, engine):\n",
    "    return openai.Engine(id=engine).embeddings(input=[text])[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def get_embeddings(text_array, engine):\n",
    "    return openai.Engine(id=engine).embeddings(input=text_array)[\"data\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def handle_file(filename):\n",
    "    contents = read_file(filename)\n",
    "    stripped_filename = filename[:-4]\n",
    "    text_embeddings, average_embedding = create_embeddings_for_text(contents)\n",
    "\n",
    "    vectors = []\n",
    "    for i, (text_chunk, embedding) in enumerate(text_embeddings):\n",
    "        id = f'{stripped_filename}/{i}'\n",
    "        file_text_dict[id] = text_chunk\n",
    "        vectors.append((id, embedding, {\"topic\": stripped_filename, \"topic_chunk_index\": i}))\n",
    "\n",
    "    batch_size = MAX_PINECONE_VECTORS_TO_UPSERT_PATCH_SIZE\n",
    "    batches = [vectors[i: i + batch_size] for i in range(0, len(vectors), batch_size)]\n",
    "\n",
    "    for batch in batches:\n",
    "        pinecone_index.upsert(vectors=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Domestic-Electricity.pdf\n",
      "Processing file: Electrical-Components.pdf\n",
      "Processing file: Electromagnetic-Induction.pdf\n",
      "Processing file: Electromagnetism.pdf\n",
      "Processing file: Electrostatics.pdf\n",
      "Processing file: Magnetism.pdf\n",
      "Processing file: Sound.pdf\n",
      "Processing file: Waves.pdf\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir('data'):\n",
    "  if not filename.endswith('.pdf') and not filename.endswith('.txt'):\n",
    "    continue\n",
    "  print(f'Processing file: {filename}')\n",
    "  handle_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('file-text-mapping.json', 'w+') as fp:\n",
    "    json.dump(file_text_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.00075,\n",
       " 'namespaces': {'': {'vector_count': 75}},\n",
       " 'total_vector_count': 75}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def answer(question):\n",
    "    search_query_embedding = get_embedding(question, EMBEDDINGS_MODEL)\n",
    "\n",
    "    try:\n",
    "        query_response = pinecone_index.query(\n",
    "            top_k=TOP_K,\n",
    "            include_values=False,\n",
    "            include_metadata=True,\n",
    "            vector=search_query_embedding,\n",
    "        )\n",
    "\n",
    "        files_string = \"Extract:\\n\"\n",
    "\n",
    "        for i in range(len(query_response.matches)):\n",
    "            result = query_response.matches[i]\n",
    "            file_chunk_id = result.id\n",
    "\n",
    "            score = result.score\n",
    "            if score < COSINE_SIM_THRESHOLD and i > 0:\n",
    "                break\n",
    "\n",
    "            topic = result.metadata[\"topic\"]\n",
    "            file_text = file_text_dict.get(file_chunk_id)\n",
    "            files_string += f\"\\nTopic: {topic}\\nContent: {file_text}\\n\"\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are an intelligent teaching assistant whose goal is to answer and explain queries from the student.\n",
    "\n",
    "Along with the student's question, you will be given extracts from the textbook (showing both topic and contents) to help you better assist the student. First, check if the student's question is related to the subject at hand (Physics). If not, reply \"This is not a valid question.\".\n",
    "\n",
    "You will then go through the extracts to find answers to the student's question. If it is not found, use your own knowledge on the topic to give a reliable and accurate answer to the student. Make references to the textbook in your answer if possible.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Question: {question}\\n{files_string}\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            messages=messages,\n",
    "            model=GENERATIVE_MODEL,\n",
    "            max_tokens=1000,\n",
    "            temperature=0.5,\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The dangers of electricity include the risk of electric shock, fires or explosions, and the potential for electrocution. \\n\\nElectric shock can occur when a person comes into contact with an electrical current. The human body can only withstand a certain amount of current, typically around 50 mA. However, if the skin is wet or if there is a path of low resistance, such as through the body's fluids, a larger electric current can flow through the body, causing an electric shock and potentially leading to injury or death. This is why it is important to be cautious around electrical devices and to avoid touching live wires or exposed electrical components.\\n\\nFires or explosions can also occur as a result of excessive build-up of electric charges produced by friction. For example, electric charges can accumulate on an aircraft during flight or on trucks transporting flammable liquids. To prevent such hazards, preventive measures can be taken, such as using slightly conductive materials to dissipate the charge build-up.\\n\\nIn addition, damp conditions can increase the risk of electric shock. If water comes into contact with a live wire, it provides a conducting path for a large amount of current to flow through it and through the body of a person.\\n\\nTo mitigate these dangers, safety precautions such as proper grounding and insulation are important. Grounding involves connecting the metal casing of an appliance to the earth wire, which acts as a low resistance path for electric current and helps protect users from electric shock. Insulation, on the other hand, prevents the exposure of conducting wires and helps maintain a safe barrier between the electrical current and the user.\\n\\nIt is important to follow safety guidelines and take precautions when dealing with electricity to minimize the risks associated with it.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"what are the dangers of electricity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}