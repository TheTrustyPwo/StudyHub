{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf2 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (1.25.2)\n",
      "Requirement already satisfied: openai in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (0.27.8)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (4.4.0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (1.26.14)\n",
      "Requirement already satisfied: loguru>=0.5.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (2.28.2)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (2.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.4 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from pinecone-client) (6.0.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\shuce\\pycharmprojects\\studyhub-server\\venv\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf2 pinecone-client scikit-learn tiktoken numpy openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuce\\PycharmProjects\\StudyHub-server\\venv\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "import tiktoken\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "from numpy import array, average\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDINGS_MODEL = \"text-embedding-ada-002\"\n",
    "GENERATIVE_MODEL = \"gpt-3.5-turbo\"\n",
    "EMBEDDING_DIMENSION = 1536\n",
    "TEXT_EMBEDDING_CHUNK_SIZE = 200\n",
    "COSINE_SIM_THRESHOLD = 0.7\n",
    "MAX_TEXTS_TO_EMBED_BATCH_SIZE = 100\n",
    "MAX_PINECONE_VECTORS_TO_UPSERT_PATCH_SIZE = 100\n",
    "TOP_K = 5\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "pinecone.init(api_key=os.getenv('PINECONE_API_KEY'), environment='gcp-starter')\n",
    "pinecone_index = pinecone.Index('studyhub')\n",
    "print(pinecone_index.describe_index_stats())\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "file_text_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def chunks(text, n):\n",
    "    \"\"\"\n",
    "    Yield successive n-sized chunks from text,\n",
    "    preferably ending at the end of a sentence.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.encode(text)\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            # Decode the tokens and check for full stop or newline\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        # If no end of sentence found, use n tokens as the chunk size\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n",
    "\n",
    "\n",
    "def get_col_average_from_list_of_lists(list_of_lists):\n",
    "    \"\"\"\n",
    "    Compute the column-wise average of a list of lists\n",
    "    \"\"\"\n",
    "    if len(list_of_lists) == 1:\n",
    "        return list_of_lists[0]\n",
    "    else:\n",
    "        list_of_lists_array = array(list_of_lists)\n",
    "        average_embedding = average(list_of_lists_array, axis=0)\n",
    "        return average_embedding.tolist()\n",
    "\n",
    "\n",
    "def create_embeddings_for_text(text):\n",
    "    \"\"\"\n",
    "    Create embeddings for a text using a tokenizer and an OpenAI engine.\n",
    "    Return a list of tuples (text_chunk, embedding) and an average embedding for a text.\n",
    "    \"\"\"\n",
    "    token_chunks = list(chunks(text, TEXT_EMBEDDING_CHUNK_SIZE))\n",
    "    text_chunks = [tokenizer.decode(chunk) for chunk in token_chunks]\n",
    "\n",
    "    # Split text_chunks into shorter arrays of max length 10\n",
    "    text_chunks_arrays = [text_chunks[i:i+MAX_TEXTS_TO_EMBED_BATCH_SIZE] for i in range(0, len(text_chunks), MAX_TEXTS_TO_EMBED_BATCH_SIZE)]\n",
    "\n",
    "    # Call get_embeddings for each shorter array and combine the results\n",
    "    embeddings = []\n",
    "    for text_chunks_array in text_chunks_arrays:\n",
    "        embeddings_response = get_embeddings(text_chunks_array, EMBEDDINGS_MODEL)\n",
    "        embeddings.extend([embedding[\"embedding\"] for embedding in embeddings_response])\n",
    "\n",
    "    text_embeddings = list(zip(text_chunks, embeddings))\n",
    "\n",
    "    average_embedding = get_col_average_from_list_of_lists(embeddings)\n",
    "\n",
    "    return text_embeddings, average_embedding\n",
    "\n",
    "def read_file(filename):\n",
    "  if filename.endswith('.pdf'):\n",
    "    reader = PdfReader(os.path.join('data', filename))\n",
    "    extracted_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        extracted_text += page.extract_text()\n",
    "  elif filename.endswith('.txt'):\n",
    "    with open(os.path.join('data', filename), 'r') as fp:\n",
    "      extracted_text = fp.read()\n",
    "\n",
    "  file_text_dict[filename[:-4]] = extracted_text\n",
    "\n",
    "  clean_text = extracted_text.replace('\\uf0b7', ' ').replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"  \", \" \")\n",
    "  return f'Topic is {filename[:-4]}; {clean_text}'\n",
    "\n",
    "\n",
    "def get_embedding(text, engine):\n",
    "    return openai.Engine(id=engine).embeddings(input=[text])[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def get_embeddings(text_array, engine):\n",
    "    return openai.Engine(id=engine).embeddings(input=text_array)[\"data\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def handle_file(filename):\n",
    "    contents = read_file(filename)\n",
    "    stripped_filename = filename[:-4]\n",
    "    text_embeddings, average_embedding = create_embeddings_for_text(contents)\n",
    "\n",
    "    vectors = []\n",
    "    for i, (text_chunk, embedding) in enumerate(text_embeddings):\n",
    "        id = f'{stripped_filename}/{i}'\n",
    "        file_text_dict[id] = text_chunk\n",
    "        vectors.append((id, embedding, {\"topic\": stripped_filename, \"topic_chunk_index\": i}))\n",
    "\n",
    "    batch_size = MAX_PINECONE_VECTORS_TO_UPSERT_PATCH_SIZE\n",
    "    batches = [vectors[i: i + batch_size] for i in range(0, len(vectors), batch_size)]\n",
    "\n",
    "    for batch in batches:\n",
    "        pinecone_index.upsert(vectors=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Domestic-Electricity.pdf\n",
      "Processing file: Electrical-Components.pdf\n",
      "Processing file: Electromagnetic-Induction.pdf\n",
      "Processing file: Electromagnetism.pdf\n",
      "Processing file: Electrostatics.pdf\n",
      "Processing file: Magnetism.pdf\n",
      "Processing file: Sound.pdf\n",
      "Processing file: Waves.pdf\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir('data'):\n",
    "  if not filename.endswith('.pdf') and not filename.endswith('.txt'):\n",
    "    continue\n",
    "  print(f'Processing file: {filename}')\n",
    "  handle_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('file-text-mapping.json', 'w+') as fp:\n",
    "    json.dump(file_text_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.00075,\n",
       " 'namespaces': {'': {'vector_count': 75}},\n",
       " 'total_vector_count': 75}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def answer(question):\n",
    "    search_query_embedding = get_embedding(question, EMBEDDINGS_MODEL)\n",
    "\n",
    "    try:\n",
    "        query_response = pinecone_index.query(\n",
    "            top_k=TOP_K,\n",
    "            include_values=False,\n",
    "            include_metadata=True,\n",
    "            vector=search_query_embedding,\n",
    "        )\n",
    "\n",
    "        files_string = \"Extract:\\n\"\n",
    "\n",
    "        for i in range(len(query_response.matches)):\n",
    "            result = query_response.matches[i]\n",
    "            file_chunk_id = result.id\n",
    "\n",
    "            score = result.score\n",
    "            if score < COSINE_SIM_THRESHOLD and i > 0:\n",
    "                break\n",
    "\n",
    "            topic = result.metadata[\"topic\"]\n",
    "            file_text = file_text_dict.get(file_chunk_id)\n",
    "            files_string += f\"\\nTopic: {topic}\\nContent: {file_text}\\n\"\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are an intelligent teaching assistant whose goal is to answer and explain queries from the student.\n",
    "\n",
    "Along with the student's question, you will be given extracts from the textbook (showing both topic and contents) to help you better assist the student. First, check if the student's question is related to the subject at hand (Physics). If not, reply \"This is not a valid question.\".\n",
    "\n",
    "You will then go through the extracts to find answers to the student's question. If it is not found, use your own knowledge on the topic to give a reliable and accurate answer to the student. Make references to the textbook in your answer if possible.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Question: {question}\\n{files_string}\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            messages=messages,\n",
    "            model=GENERATIVE_MODEL,\n",
    "            max_tokens=1000,\n",
    "            temperature=0.5,\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(topic):\n",
    "    search_query_embedding = get_embedding(topic, EMBEDDINGS_MODEL)\n",
    "    \n",
    "    query_response = pinecone_index.query(\n",
    "        top_k=TOP_K,\n",
    "        include_values=False,\n",
    "        include_metadata=True,\n",
    "        vector=search_query_embedding,\n",
    "        filter={'topic': topic}\n",
    "    )\n",
    "\n",
    "    files_string = \"Extracts:\\n\"\n",
    "\n",
    "    for i in range(len(query_response.matches)):\n",
    "        result = query_response.matches[i]\n",
    "        file_chunk_id = result.id\n",
    "\n",
    "        score = result.score\n",
    "        if score < COSINE_SIM_THRESHOLD and i > 0:\n",
    "            break\n",
    "\n",
    "        topic = result.metadata[\"topic\"]\n",
    "        file_text = file_text_dict.get(file_chunk_id)\n",
    "        files_string += f\"\\nTopic: {topic}\\nContent: {file_text}\\n\"\n",
    "\n",
    "    print(files_string)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a knowledgeable educator preparing a test for your students based on a given topic.\n",
    "\n",
    "You will be given extracts from the textbook to help you better craft a question.\n",
    "You will then go through the extracts and create a suitable question to test the student, and you have to make sure to create the answer as well.\n",
    "Vary the questions you craft and make them difficult.\n",
    "\n",
    "Format your response in JSON format: {\"question\": question, \"answer\": answer}\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Topic: {topic}\\n{files_string}\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        messages=messages,\n",
    "        model=GENERATIVE_MODEL,\n",
    "        max_tokens=1000,\n",
    "        temperature=1.0,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracts:\n",
      "\n",
      "Topic: Electrostatics\n",
      "Content: Topic is Electrostatics; /Sec4/Phy sics/Electrostatics  Page 1 of 11 Hwa Chong Institution (High School) Name : _________________________ (   ) PHYSICS Notes Class : __________  Electrostatics Date : __________  Note: You should read your text book and compare with these notes.   A. Introduction Some objects (e.g. glass ro d or ebonite rod) acquire a new property of being able to attract small pieces of paper after they have been rubbed with another material (e.g. silk or fur, respectively). This phenomenon belongs to the branch of physics called electrostatics or static electricity . It involves the study of static electric charges. Before rubbing, these objects do not attract small pieces of paper. This implies that friction due to rubbing has changed the nature of the surfaces of the rods. We say that friction has caused the rods to be ‘electrified’ or ‘charged’.   B. Two types of charges  Only two kinds of charges exist: positive charge and negative charge. (note: in every case, equal amount of opposite charges are formed)    C. Separation of charges  a)  By Friction  1. Rub polythene strip with a duster as shown in Fig (a). Test the polythene strip and the duster with an electroscope.\n",
      "\n",
      "Topic: Electrostatics\n",
      "Content:  This means that the strength of the field is stronger nearer the charge, and decreases further away from the charge.   The figure illustrates a uniform electric field between two parallel oppositely charged plates. The electric lines of force at the central region are parallel to each other and equally spaced. The greater number of lines indicates a stronger uniform electric field.  The following figure shows the field pattern set up by a pair of charges placed close together   G. Applications and Hazards of Electrostatics  a) Some applications  1. Flue-ash removal              /Sec4/ Physics/Electrostatics  Page 10 of 11 One important application is the removal of flue -ash (a mixture of smoke and dust particles) from a modern coal -fired power station by means of an electrostatic precipitator. If the flue - ash is not removed, it would be discharged into the atmosphere causing serious air pollution. The figure shows how a precipitator attached to the chimney walls removes smoke and dust particles from the waste gases that flow through the chimney into the atmosphere. A precipitator is made up of a number of wires and plates. The wires are made negatively charged so that they can charge the ash particles negatively when passing through.  The collector plates are made positively charged to attract and collect the ash particles.\n",
      "\n",
      "Topic: Electrostatics\n",
      "Content:   − In both figures, the purpose of the insulating stand is to prevent any electron flow between the charged metal sphere and the earth. The human body is a relatively good conductor and therefore acts as a conducting path for the electrons.   b) By Electrostatic Induction  1. A simple experiment The figure shows a light polystyrene sphere which has been coated with a metal (conducting) paint suspended near a positively charged strip. The metal sphere is seen to move towards the positive strip. This phenomena occurs because of electrostatic induction.  2. Why do charges separate due to induction? The metal ‘coated’ sphere is standing in the electric field set up by the charge on the acetate strip. This field causes the separation of equal amounts of charge on the sphere by induction (influence). Negative charges from within the neutral metal move towards the end nearer the positive strip leaving positive charges at the side of the sphere furthest from the strip.    /Sec4/ Physics/Electrostatics  Page 5 of 11 3. Some examples of separation of charges by induction (i) To charge two conductors with equal and opposite charges  Step 1: The two conductors (metallic spheres) on insulator stands are brought into contact with one another. Step 2: A negatively char ged rod is brought near to sphere A . This causes the electrons from A to be repelled to the remote side of B .\n",
      "\n",
      "Topic: Electrostatics\n",
      "Content:  The plates are then mechanically shaken to remove the ash which is collected and used as a by - product. The electrostatic precipitation technique is also important in steel, cement and chemical industries which release large quan tities of flue gases.   2. Spray painting  Where mass automation is required, such as in car production, electrostatic spray painting is commonly used. The object (such as a car’s body) to be sprayed and the spray nozzle (and hence the paint) are given opposite charges. This will result in good adhesion of the paint to every corner of the object to give a uniform layer of paint. This method is effective, efficient and economical.   3. Photocopier            /Sec4/ Physics/Electrostatics  Page 11 of 11 3. Laser Printer        b) Some ha zards  1. Lightning  This is due to a large quantity of electric charge being built up in the heavy thunderclouds. The thunderclouds are charged by friction between the water molecules in the thunderclouds and the air molecules. When the charge on the thunderclouds is sufficiently large, it can ionise the air which then provides a conducting path for the huge quantity of charge to be discharged to the nearest or sharpest object on the ground.\n",
      "\n",
      "Topic: Electrostatics\n",
      "Content:  The region in which force is exerted  is called an electric field , and it extends an infinite distance away. An uncharged metal sphere (in the figure) on an insulating stand has no external electric effect. It does contain many electric charges but, since these are present in equal and opposi te amounts, the overall effect is electric neutrality.     /Sec4/ Physics/Electrostatics  Page 8 of 11 If a metal sphere A [as shown in Fig (a)] acquires a small positive charge (by the removal of negative charges from the sphere), the charge acquired can exert a force of attraction on negative charges and a force of repulsion on positive charges. The acquisition of the positive charge is said to raise the electric potential of the sphere so that it is greater than that of the Earth (taken as zero potential). A small positive charge raises the sphere t o a ‘small’ positive potential +v. If an identical sphere B [as shown in Fig (b)] were to acquire more positive charge it would be raised to an even higher positive potential +V . Hence sphere B is at a higher positive potential than sphere A .  If the spheres B and A are connected by an insulated wire as shown in the figure, charge will flow because of the potential difference ( V - v) between the two spheres.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"question\": \"What is the purpose of an electrostatic precipitator?\", \"answer\": \"To remove flue-ash (a mixture of smoke and dust particles) from a modern coal-fired power station and prevent air pollution.\"}'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate('Electrostatics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}